{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ0mMXhuukgjccGvJHCjG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveengovianalytics/Memory_Plus_Agency_Your_AI/blob/main/Memory%2BAgency_%3D_AI_That_Understands_you.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "When AI agents operate without memory, they encounter several significant limitations that impact usability, coherence, and effectiveness:\n",
        "\n",
        "# 🚫 1. Context Amnesia (Short-Term)\n",
        "Without any form of memory, each user input is treated in isolation—agents can’t recall previous turns, even within the same chat.\n",
        "\n",
        "Leads to broken conversations: forgotten names, tasks, or preferences mid-session\n",
        "\n",
        "Example: a trip-planning assistant forgetting earlier details like destination or dates breaks continuity .\n",
        "\n",
        "#🧠 2. No Personalization or Learning (Long-Term)\n",
        "Stateless agents lack the ability to learn from past sessions or build user profiles over time.\n",
        "\n",
        "They can’t remember facts about the user, their preferences, ongoing projects, or past decisions\n",
        "\n",
        "This results in repetitive prompts (“What’s your birthday again?”) and hinders long-term engagement.\n",
        "\n",
        "# 🤖 3. Inability to Handle Complex, Multi-Step Tasks\n",
        "Tasks that require planning or multi-step execution over time are severely impacted.\n",
        "\n",
        "Without memory, agents can't pause, recall progress, or resume workflows.\n",
        "\n",
        "Autonomous systems like AutoGPT illustrate this: lacking memory leads to repeated loops or forgotten subtasks"
      ],
      "metadata": {
        "id": "5VtWMFWuxefL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Basics\n"
      ],
      "metadata": {
        "id": "9dihHhhuw05t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 1. Semantic Memory\n",
        "What it is: A long-term knowledge base of facts, definitions, concepts, and user-specific attributes.\n",
        "When to use it:\n",
        "\n",
        "To ground responses in factual knowledge (e.g. \"Paris is capital of France\")\n",
        "\n",
        "To store persistent user preferences or profiles\n",
        "\n",
        "To answer queries requiring domain knowledge\n",
        "Benefits: Adds consistency and enables personalization across sessions\n",
        "Example: Storing that a user prefers quick recipes or morning updates\n",
        "\n",
        "\n",
        "# 🪞 2. Episodic Memory\n",
        "What it is: A collection of past user interactions or specific agent actions.\n",
        "When to use it:\n",
        "\n",
        "To maintain context across turns or sessions\n",
        "\n",
        "To refer back to past decisions (\"You asked about Xmas gifts last time\")\n",
        "\n",
        "For case-based reasoning (learn from prior successes/failures)\n",
        "Benefits: Supports continuity and personalized follow-ups\n",
        "Example: Reminding the user of their previous project summary\n",
        "\n",
        "# ⚙️ 3. Procedural Memory\n",
        "What it is: The agent’s internal workflows, reasoning steps, and instructions—essentially how it operates.\n",
        "When to use it:\n",
        "\n",
        "To preserve and reuse refined prompts or reasoning strategies\n",
        "\n",
        "To enforce task-specific procedures or tool invocation rules\n",
        "\n",
        "For agents that self-optimize over time\n",
        "Benefits: Ensures consistency, reliability, and improves over time\n",
        "Example: Keeping a refined system prompt to handle financial queries"
      ],
      "metadata": {
        "id": "e_DfUPExw3T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo"
      ],
      "metadata": {
        "id": "qc-hdlvBxDwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval-Augmented Generation (RAG) Agent using LangMem for long‑term memory and OpenAI’s Agent SDK for tool-driven scraping, embedding, retrieval, and generation:"
      ],
      "metadata": {
        "id": "xVl678_wqfjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 1"
      ],
      "metadata": {
        "id": "g1YUXyQ1xvcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langmem openai langgraph tiktoken pydantic beautifulsoup4 requests -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2lukvTBqWNU",
        "outputId": "0f823453-12d4-42dd-fbd1-8c29d38d2b53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"openai_api_key\")"
      ],
      "metadata": {
        "id": "1o09uyrPqlXY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 1. Setup LangMem for Long‑Term Memory"
      ],
      "metadata": {
        "id": "v5NNW9G8q7v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "\n",
        "# 1. Setup your LLM model\n",
        "model = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
        "\n",
        "# 2. Prepare memory store and tools\n",
        "store = InMemoryStore(\n",
        "    index={\"dims\": 1536, \"embed\": \"openai:text-embedding-3-small\"}\n",
        ")\n",
        "\n",
        "# Create LangMem tools for semantic, episodic, procedural memory\n",
        "manage_sem = create_manage_memory_tool(namespace=(\"semantic\",), store=store)\n",
        "search_sem = create_search_memory_tool(namespace=(\"semantic\",), store=store)\n",
        "\n",
        "manage_epi = create_manage_memory_tool(namespace=(\"episodic\",), store=store)\n",
        "search_epi = create_search_memory_tool(namespace=(\"episodic\",), store=store)\n",
        "\n",
        "manage_proc = create_manage_memory_tool(namespace=(\"procedural\",), store=store)\n",
        "search_proc = create_search_memory_tool(namespace=(\"procedural\",), store=store)\n",
        "\n",
        "tools = [\n",
        "    manage_sem, search_sem,\n",
        "    manage_epi, search_epi,\n",
        "    manage_proc, search_proc,\n",
        "]\n",
        "\n",
        "# 3. Create a checkpointer for short-term memory across turns\n",
        "checkpointer = InMemorySaver()\n",
        "\n",
        "# 4. Build the agent\n",
        "agent = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools,\n",
        "    prompt=\"You are a RAG agent with semantic, episodic, and procedural memory.\",\n",
        "    checkpointer=checkpointer,\n",
        "    store=store,  # needed so memory tools know where to store\n",
        "    debug=True\n",
        ")"
      ],
      "metadata": {
        "id": "wpBD75eerpWx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"session-123\"}}\n",
        "\n",
        "# Turn 1\n",
        "out1 = agent.invoke(\n",
        "    {\"messages\": [{\"role\":\"user\",\"content\":\"Hi, remember I prefer dark mode?\"}]},\n",
        "    config\n",
        ")\n",
        "\n",
        "# Turn 2: memory retrieved automatically\n",
        "out2 = agent.invoke(\n",
        "    {\"messages\": [{\"role\":\"user\",\"content\":\"What’s my display preference?\"}]},\n",
        "    config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICZxNHber8C6",
        "outputId": "1968f440-153a-4c0a-b253-f174307399f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
            "\u001b[0m{'messages': []}\n",
            "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [{'content': 'Hi, remember I prefer dark mode?', 'role': 'user'}]}\n",
            "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [{'content': 'Hi, remember I prefer dark mode?', 'role': 'user'}]\n",
            "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48')]}\n",
            "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
            " 'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48')],\n",
            " 'remaining_steps': 24}\n",
            "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> [{'args': {'content': 'The user prefers dark mode.'},\n",
            "  'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs',\n",
            "  'name': 'manage_memory',\n",
            "  'type': 'tool_call'}]\n",
            "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs')]\n",
            "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs')]}\n",
            "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 1 task for step 3:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
            " 'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs')],\n",
            " 'remaining_steps': 22}\n",
            "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\u001b[36;1m\u001b[1;3m[4:checkpoint]\u001b[0m \u001b[1mState at the end of step 4:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\u001b[36;1m\u001b[1;3m[5:tasks]\u001b[0m \u001b[1mStarting 1 task for step 5:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [{'content': 'What’s my display preference?', 'role': 'user'}]}\n",
            "\u001b[36;1m\u001b[1;3m[5:writes]\u001b[0m \u001b[1mFinished step 5 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [{'content': 'What’s my display preference?', 'role': 'user'}]\n",
            "\u001b[36;1m\u001b[1;3m[5:checkpoint]\u001b[0m \u001b[1mState at the end of step 5:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              HumanMessage(content='What’s my display preference?', additional_kwargs={}, response_metadata={}, id='a72ef718-3355-4eff-92e1-2b2b720556fe')]}\n",
            "\u001b[36;1m\u001b[1;3m[6:tasks]\u001b[0m \u001b[1mStarting 1 task for step 6:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
            " 'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              HumanMessage(content='What’s my display preference?', additional_kwargs={}, response_metadata={}, id='a72ef718-3355-4eff-92e1-2b2b720556fe')],\n",
            " 'remaining_steps': 24}\n",
            "\u001b[36;1m\u001b[1;3m[6:writes]\u001b[0m \u001b[1mFinished step 6 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'function': {'arguments': '{\"query\":\"display preference\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 370, 'total_tokens': 385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdide3czw6YVUib9hkOe6Vf0ADjo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--219de1f6-d459-4a9d-b0f3-dd4c03509270-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'display preference'}, 'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 370, 'output_tokens': 15, 'total_tokens': 385, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\u001b[36;1m\u001b[1;3m[6:checkpoint]\u001b[0m \u001b[1mState at the end of step 6:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              HumanMessage(content='What’s my display preference?', additional_kwargs={}, response_metadata={}, id='a72ef718-3355-4eff-92e1-2b2b720556fe'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'function': {'arguments': '{\"query\":\"display preference\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 370, 'total_tokens': 385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdide3czw6YVUib9hkOe6Vf0ADjo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--219de1f6-d459-4a9d-b0f3-dd4c03509270-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'display preference'}, 'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 370, 'output_tokens': 15, 'total_tokens': 385, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\u001b[36;1m\u001b[1;3m[7:tasks]\u001b[0m \u001b[1mStarting 1 task for step 7:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> [{'args': {'query': 'display preference'},\n",
            "  'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw',\n",
            "  'name': 'search_memory',\n",
            "  'type': 'tool_call'}]\n",
            "\u001b[36;1m\u001b[1;3m[7:writes]\u001b[0m \u001b[1mFinished step 7 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='[{\"namespace\":[\"procedural\"],\"key\":\"9e4da5f0-2fec-4447-9cfe-78cb5c1888cb\",\"value\":{\"content\":\"The user prefers dark mode.\"},\"created_at\":\"2025-06-26T10:02:00.996905+00:00\",\"updated_at\":\"2025-06-26T10:02:00.996911+00:00\",\"score\":0.38828745992629937}]', name='search_memory', tool_call_id='call_osKgCXQ0nQ46hyVb26HhXhYw')]\n",
            "\u001b[36;1m\u001b[1;3m[7:checkpoint]\u001b[0m \u001b[1mState at the end of step 7:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              HumanMessage(content='What’s my display preference?', additional_kwargs={}, response_metadata={}, id='a72ef718-3355-4eff-92e1-2b2b720556fe'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'function': {'arguments': '{\"query\":\"display preference\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 370, 'total_tokens': 385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdide3czw6YVUib9hkOe6Vf0ADjo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--219de1f6-d459-4a9d-b0f3-dd4c03509270-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'display preference'}, 'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 370, 'output_tokens': 15, 'total_tokens': 385, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='[{\"namespace\":[\"procedural\"],\"key\":\"9e4da5f0-2fec-4447-9cfe-78cb5c1888cb\",\"value\":{\"content\":\"The user prefers dark mode.\"},\"created_at\":\"2025-06-26T10:02:00.996905+00:00\",\"updated_at\":\"2025-06-26T10:02:00.996911+00:00\",\"score\":0.38828745992629937}]', name='search_memory', id='c3e50711-91e6-41b2-91b0-819801039dcf', tool_call_id='call_osKgCXQ0nQ46hyVb26HhXhYw')]}\n",
            "\u001b[36;1m\u001b[1;3m[8:tasks]\u001b[0m \u001b[1mStarting 1 task for step 8:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
            " 'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              HumanMessage(content='What’s my display preference?', additional_kwargs={}, response_metadata={}, id='a72ef718-3355-4eff-92e1-2b2b720556fe'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'function': {'arguments': '{\"query\":\"display preference\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 370, 'total_tokens': 385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdide3czw6YVUib9hkOe6Vf0ADjo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--219de1f6-d459-4a9d-b0f3-dd4c03509270-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'display preference'}, 'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 370, 'output_tokens': 15, 'total_tokens': 385, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='[{\"namespace\":[\"procedural\"],\"key\":\"9e4da5f0-2fec-4447-9cfe-78cb5c1888cb\",\"value\":{\"content\":\"The user prefers dark mode.\"},\"created_at\":\"2025-06-26T10:02:00.996905+00:00\",\"updated_at\":\"2025-06-26T10:02:00.996911+00:00\",\"score\":0.38828745992629937}]', name='search_memory', id='c3e50711-91e6-41b2-91b0-819801039dcf', tool_call_id='call_osKgCXQ0nQ46hyVb26HhXhYw')],\n",
            " 'remaining_steps': 22}\n",
            "\u001b[36;1m\u001b[1;3m[8:writes]\u001b[0m \u001b[1mFinished step 8 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='You prefer dark mode for your display. If you have any other preferences or changes, feel free to tell me!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 497, 'total_tokens': 521, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdifz5tikEGPqmz6LnAhhAdCjloz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--67848697-4677-4722-99cd-74e917bf4f5b-0', usage_metadata={'input_tokens': 497, 'output_tokens': 24, 'total_tokens': 521, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\u001b[36;1m\u001b[1;3m[8:checkpoint]\u001b[0m \u001b[1mState at the end of step 8:\n",
            "\u001b[0m{'messages': [HumanMessage(content='Hi, remember I prefer dark mode?', additional_kwargs={}, response_metadata={}, id='dc79129c-0162-4d88-8a03-e2b5ad170a48'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'function': {'arguments': '{\"content\":\"The user prefers dark mode.\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 272, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdiXidCzEn9s2hCLEwx71SHbaroB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--94135445-ddc5-4674-bc95-08395eb88227-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'The user prefers dark mode.'}, 'id': 'call_lbarBmHN6GVIzxgIP6DK9tYs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 272, 'output_tokens': 19, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='created memory 9e4da5f0-2fec-4447-9cfe-78cb5c1888cb', name='manage_memory', id='11867476-73ac-4503-a791-ee7528a265ad', tool_call_id='call_lbarBmHN6GVIzxgIP6DK9tYs'),\n",
            "              AIMessage(content=\"Got it! I've noted that you prefer dark mode. If there's anything else you'd like me to remember, just let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 327, 'total_tokens': 357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-BmdibdRjXpn3XumRSpYMbq6egRamz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4585d6e2-94fa-4380-99a7-c9bbd9b79056-0', usage_metadata={'input_tokens': 327, 'output_tokens': 30, 'total_tokens': 357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              HumanMessage(content='What’s my display preference?', additional_kwargs={}, response_metadata={}, id='a72ef718-3355-4eff-92e1-2b2b720556fe'),\n",
            "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'function': {'arguments': '{\"query\":\"display preference\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 370, 'total_tokens': 385, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdide3czw6YVUib9hkOe6Vf0ADjo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--219de1f6-d459-4a9d-b0f3-dd4c03509270-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'display preference'}, 'id': 'call_osKgCXQ0nQ46hyVb26HhXhYw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 370, 'output_tokens': 15, 'total_tokens': 385, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
            "              ToolMessage(content='[{\"namespace\":[\"procedural\"],\"key\":\"9e4da5f0-2fec-4447-9cfe-78cb5c1888cb\",\"value\":{\"content\":\"The user prefers dark mode.\"},\"created_at\":\"2025-06-26T10:02:00.996905+00:00\",\"updated_at\":\"2025-06-26T10:02:00.996911+00:00\",\"score\":0.38828745992629937}]', name='search_memory', id='c3e50711-91e6-41b2-91b0-819801039dcf', tool_call_id='call_osKgCXQ0nQ46hyVb26HhXhYw'),\n",
            "              AIMessage(content='You prefer dark mode for your display. If you have any other preferences or changes, feel free to tell me!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 497, 'total_tokens': 521, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_de235176ee', 'id': 'chatcmpl-Bmdifz5tikEGPqmz6LnAhhAdCjloz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--67848697-4677-4722-99cd-74e917bf4f5b-0', usage_metadata={'input_tokens': 497, 'output_tokens': 24, 'total_tokens': 521, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Take Away\n",
        "With this setup, your agent can remember preferences (semantic), recall past interaction episodes (episodic), and maintain or adapt its behavior guidelines (procedural), all within the ReAct framework. You can also add tools for RAG retrieval such as web scraping or database lookup, embedding and storing in the same InMemoryStore. Want to see how to wire in a scraper for RAG?"
      ],
      "metadata": {
        "id": "SQb-P69tsJvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Memory to ScrapAny Web Agent"
      ],
      "metadata": {
        "id": "LJDW7BGAtuNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vQv_BlAWs1Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "\n",
        "# 🛠️ 1. Define the web scraper tool for RAG\n",
        "def scrape_url(url: str) -> str:\n",
        "    \"\"\"Scrapes visible text from a webpage.\"\"\"\n",
        "    resp = requests.get(url, timeout=10)\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    for tag in soup(['script', 'style']):\n",
        "        tag.decompose()\n",
        "    return soup.get_text(separator='\\n').strip()\n",
        "\n",
        "# 2. Memory store setup\n",
        "store = InMemoryStore(index={\"dims\":1536, \"embed\":\"openai:text-embedding-3-small\"})\n",
        "\n",
        "# 3. Memory tools for semantic, episodic, and procedural memory\n",
        "sem_m = create_manage_memory_tool(namespace=(\"semantic\",), store=store)\n",
        "sem_s = create_search_memory_tool(namespace=(\"semantic\",), store=store)\n",
        "epi_m = create_manage_memory_tool(namespace=(\"episodic\",), store=store)\n",
        "epi_s = create_search_memory_tool(namespace=(\"episodic\",), store=store)\n",
        "proc_m = create_manage_memory_tool(namespace=(\"procedural\",), store=store)\n",
        "proc_s = create_search_memory_tool(namespace=(\"procedural\",), store=store)\n",
        "\n",
        "# 4. Bundle tools (including scraper)\n",
        "tools = [scrape_url, sem_m, sem_s, epi_m, epi_s, proc_m, proc_s]  # total 7\n",
        "\n",
        "# 5. Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
        "\n",
        "# 6. Create RAG + Memory agent\n",
        "agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=tools,\n",
        "    prompt=\"You are a RAG agent with memory: can scrape the web and remember facts, episodes, and behavior.\",\n",
        "    checkpointer=InMemorySaver(),\n",
        "    store=store,\n",
        "    debug=True\n",
        ")"
      ],
      "metadata": {
        "id": "r-d-X1xRsI0Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "\n",
        "# 🛠️ 1. Define scraper tool with a docstring\n",
        "@tool\n",
        "def scrape_url(url: str) -> str:\n",
        "    \"\"\"Scrape the visible text content from a webpage URL.\"\"\"\n",
        "    resp = requests.get(url, timeout=10)\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    for tag in soup([\"script\", \"style\"]):\n",
        "        tag.decompose()\n",
        "    return soup.get_text(separator=\"\\n\").strip()\n",
        "\n",
        "# 2. Memory store and memory tools (semantic, episodic, procedural)\n",
        "store = InMemoryStore(index={\"dims\": 1536, \"embed\": \"openai:text-embedding-3-small\"})\n",
        "sem_m = create_manage_memory_tool(namespace=(\"semantic\",), store=store)\n",
        "sem_s = create_search_memory_tool(namespace=(\"semantic\",), store=store)\n",
        "epi_m = create_manage_memory_tool(namespace=(\"episodic\",), store=store)\n",
        "epi_s = create_search_memory_tool(namespace=(\"episodic\",), store=store)\n",
        "proc_m = create_manage_memory_tool(namespace=(\"procedural\",), store=store)\n",
        "proc_s = create_search_memory_tool(namespace=(\"procedural\",), store=store)\n",
        "\n",
        "# 3. Bundle tools\n",
        "tools = [scrape_url, sem_m, sem_s, epi_m, epi_s, proc_m, proc_s]  # total 7 tools\n",
        "\n",
        "# 4. Initialize LLM and create RAG + Memory agent\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
        "agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=tools,\n",
        "    prompt=\"You are a RAG agent with memory; you can scrape webpages and remember facts, episodes, and behavior.\",\n",
        "    checkpointer=InMemorySaver(),\n",
        "    store=store,\n",
        "    debug=True\n",
        ")\n",
        "\n",
        "def chat_cli():\n",
        "    print(\"🎯 Welcome! Type 'exit' to quit.\")\n",
        "    config = {\"configurable\": {\"thread_id\": \"cli-session\"}}\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if not user_input or user_input.lower() == \"exit\":\n",
        "            break\n",
        "        resp = agent.invoke(\n",
        "            {\"messages\": [{\"type\": \"human\", \"content\": user_input}]},\n",
        "            config\n",
        "        )\n",
        "        for msg in resp[\"messages\"]:\n",
        "            if msg.type == \"assistant\":\n",
        "                print(\"Agent:\", msg.content, \"\\n\")\n",
        "                break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat_cli()"
      ],
      "metadata": {
        "id": "l5m38zCHtswS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rfaVPJSnvZRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w1og-I96yIg5"
      }
    }
  ]
}